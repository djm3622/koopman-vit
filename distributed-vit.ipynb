{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce169423-3e3a-44f0-b38d-cb69e8aa6bf4",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Notebook for distriputed training of koopman operator model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013afb49-8586-42ba-baca-e639baf1d16f",
   "metadata": {},
   "source": [
    "# Imports/Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ece1a5-285a-4c11-861f-a6844f3ddd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator, notebook_launcher\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import data\n",
    "import dataset\n",
    "import model\n",
    "import evaluation\n",
    "import training\n",
    "import distributed\n",
    "from torch import nn\n",
    "from diffusers import UNet2DModel\n",
    "from transformers import ViTModel, ViTConfig\n",
    "import torch.optim as optim\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f52713-7c77-4e60-900c-acd9ee1bdf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # dataset\n",
    "    path = '/data/users/jupyter-dam724/colliding_solutions'\n",
    "    solver = 'ros2'\n",
    "    fixed_seq_len = 216\n",
    "    batch_size = 16\n",
    "    ahead = 1\n",
    "    tail = 1\n",
    "    aug = False\n",
    "    \n",
    "    # device\n",
    "    device_pref = 'cuda'\n",
    "    device_ind = None\n",
    "    \n",
    "    # model\n",
    "    epoches = 30\n",
    "    patience = 10\n",
    "    lr = 1e-5\n",
    "    save_path = '/data/users/jupyter-dam724/koopman-vit/checkpoint/'\n",
    "    from_checkpoint = None\n",
    "    p = False\n",
    "    latent_size = 2048\n",
    "    heads = latent_size // 64\n",
    "    \n",
    "    # distribution\n",
    "    processes = 2\n",
    "    batch_size = batch_size * processes\n",
    "    tworkers = 32\n",
    "    vworkers = 32\n",
    "    grad_accumulate = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f831c777-4f2e-4d41-b9fb-d991260fe134",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68601ec4-c0ac-45ff-afbc-b5a2dbec782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(batch, model, criterion):\n",
    "    x, y = batch\n",
    "    loss = criterion(*model(x, y))\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868124c4-2043-4813-a2b0-6e9c2131b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acelerate_ddp():\n",
    "    accelerator = Accelerator(gradient_accumulation_steps=Config.grad_accumulate)\n",
    "    \n",
    "    data_params = {\n",
    "        'path': Config.path, \n",
    "        'device_pref': Config.device_pref, \n",
    "        'solver': Config.solver, \n",
    "        'fixed_seq_len': Config.fixed_seq_len, \n",
    "        'ahead': Config.ahead, \n",
    "        'tail': Config.tail,\n",
    "        'device_ind': Config.device_ind\n",
    "    }\n",
    "\n",
    "    _, (x_train_data, y_train_data), (x_valid_data, y_valid_data) = data.main(**data_params)\n",
    "    \n",
    "    dataset_params = {\n",
    "        'x_train_data': x_train_data, \n",
    "        'y_train_data': y_train_data, \n",
    "        'x_valid_data': x_valid_data, \n",
    "        'y_valid_data': y_valid_data, \n",
    "        'batch_size': Config.batch_size,\n",
    "        'tworkers': Config.tworkers, \n",
    "        'vworkers': Config.vworkers,\n",
    "        'aug': Config.aug\n",
    "    }\n",
    "\n",
    "    train_dl, valid_dl = dataset.main(**dataset_params)\n",
    "    \n",
    "    vitconfig = ViTConfig(\n",
    "        hidden_size=Config.latent_size,         \n",
    "        num_attention_heads=Config.heads,   \n",
    "        intermediate_size=4096, \n",
    "        num_hidden_layers=12,\n",
    "        num_channels=3\n",
    "    ) \n",
    "    vit = ViTModel(vitconfig)\n",
    "    model.unfreeze(vit)\n",
    "    vitOperator = model.ViTOperatorFlex(\n",
    "        vit, \n",
    "        batch_size=Config.batch_size, \n",
    "        p=Config.p, \n",
    "        latent_size=Config.latent_size\n",
    "    )\n",
    "    \n",
    "    if Config.from_checkpoint is not None:\n",
    "        state_dict = load_file(Config.from_checkpoint)\n",
    "        vitOperator.load_state_dict(state_dict)\n",
    "\n",
    "    optimizer = optim.AdamW(vitOperator.parameters(), lr=Config.lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, threshold=1e-3)\n",
    "    \n",
    "    # Send everything through `accelerator.prepare`\n",
    "    train_dl, valid_dl, vitOperator, optimizer, scheduler = accelerator.prepare(\n",
    "        train_dl, valid_dl, vitOperator, optimizer, scheduler\n",
    "    )\n",
    "        \n",
    "    train_log, valid_log = [], []\n",
    "    \n",
    "    training_params = {\n",
    "        'accelerator': accelerator,\n",
    "        'train': train_dl, \n",
    "        'valid': valid_dl, \n",
    "        'model': vitOperator, \n",
    "        'epochs': Config.epoches, \n",
    "        'patience': Config.patience, \n",
    "        'criterion': model.OperatorLoss(1.0), \n",
    "        'save_path': Config.save_path, \n",
    "        'step': step, \n",
    "        'train_log': train_log, \n",
    "        'valid_log': valid_log, \n",
    "        'optimizer': optimizer, \n",
    "        'scheduler': scheduler, \n",
    "        'loading_bar': False\n",
    "    }\n",
    "    \n",
    "    training.accelerator_train(**training_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92728c-f611-4fdc-a233-21716cd4c8a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n",
      "Now using GPU.\n",
      "Now using GPU.\n",
      "Train size: 139607, Percent of toal: 74.66%, Unique instances: 700\n",
      "Train size: 47394, Percent of toal: 25.34%, Unique instances: 240\n",
      "Train size: 139607, Percent of toal: 74.66%, Unique instances: 700\n",
      "Train size: 47394, Percent of toal: 25.34%, Unique instances: 240\n",
      "Epoch 1/30, Train Loss: 45.123804167616754, Validation Loss: 37.27319822569151\n",
      "Epoch 2/30, Train Loss: 30.106785648735986, Validation Loss: 24.34978584083351\n",
      "Epoch 3/30, Train Loss: 21.60133946002049, Validation Loss: 19.219888980968577\n",
      "Epoch 4/30, Train Loss: 17.63250692455881, Validation Loss: 16.66112452970969\n",
      "Epoch 5/30, Train Loss: 15.904254290665142, Validation Loss: 15.344738470541465\n",
      "Epoch 6/30, Train Loss: 15.14991004092056, Validation Loss: 14.78170838484893\n",
      "Epoch 7/30, Train Loss: 14.749128958218035, Validation Loss: 14.574717275516408\n",
      "Epoch 8/30, Train Loss: 14.40631745289029, Validation Loss: 14.376058572047466\n",
      "Epoch 9/30, Train Loss: 14.189087448837231, Validation Loss: 14.016117489015734\n",
      "Epoch 10/30, Train Loss: 13.977563874648284, Validation Loss: 14.012136781537855\n",
      "Epoch 11/30, Train Loss: 13.759980069229986, Validation Loss: 13.745979992119041\n",
      "Epoch 12/30, Train Loss: 13.642070451934968, Validation Loss: 13.76304077844362\n",
      "Epoch 13/30, Train Loss: 13.451302908801638, Validation Loss: 13.35790478474385\n",
      "Epoch 14/30, Train Loss: 13.41332309981761, Validation Loss: 13.415871689770674\n",
      "Epoch 15/30, Train Loss: 13.253174588528317, Validation Loss: 13.222847491341668\n",
      "Epoch 16/30, Train Loss: 13.146027818178704, Validation Loss: 13.179471579113523\n",
      "Epoch 17/30, Train Loss: 13.024139828880902, Validation Loss: 13.042810139784942\n",
      "Epoch 18/30, Train Loss: 12.955418601160693, Validation Loss: 13.16322195852125\n",
      "Epoch 19/30, Train Loss: 12.817093958498305, Validation Loss: 12.852450378521068\n",
      "Epoch 20/30, Train Loss: 12.799766653778901, Validation Loss: 12.8995717783232\n",
      "Epoch 21/30, Train Loss: 12.677584390583414, Validation Loss: 12.741442891713735\n",
      "Epoch 22/30, Train Loss: 12.60301972747341, Validation Loss: 12.774071710174148\n",
      "Epoch 23/30, Train Loss: 12.559107920818512, Validation Loss: 12.666776477968371\n",
      "Epoch 24/30, Train Loss: 12.8419498472463, Validation Loss: 12.921554065395046\n",
      "Epoch 25/30, Train Loss: 12.693882422291976, Validation Loss: 12.747376780896573\n",
      "Epoch 26/30, Train Loss: 12.373146327358493, Validation Loss: 12.482368951230436\n",
      "Epoch 27/30, Train Loss: 12.329628121464802, Validation Loss: 12.450922312607636\n"
     ]
    }
   ],
   "source": [
    "notebook_launcher(acelerate_ddp, args=(), num_processes=Config.processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c79f3-24dc-4aa1-b850-914efb3f1399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a notebook for unet next\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa43fc7-15cb-4de9-aa71-fd01004cd6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b758b-502f-49b6-a479-6d268b77813f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
